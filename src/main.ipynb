{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list =[\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'libpng',\n",
    "    'libssh', 'libxml2',\n",
    "    'pcre', 'proj4',\n",
    "    'r32', 'sqlite3',\n",
    "    'vorbis', 'woff2',\n",
    "    'wpantund'\n",
    "]\n",
    "\n",
    "version = 'version3'\n",
    "proj_list = [\n",
    "    'total_aspell', 'total_boringssl', 'total_c-ares', 'total_exiv2',\n",
    "    'total_freetype2', 'total_grok', 'total_guetzli', 'total_harfbuzz',\n",
    "    'total_lcms', 'total_libarchive', 'total_libexif', 'total_libhtp',\n",
    "    'total_libpng', 'total_libsndfile', 'total_libssh', 'total_libxml2',\n",
    "    'total_ndpi', 'total_openthread', 'total_pcre2', 'total_proj4',\n",
    "    'total_re2', 'total_sqlite3', 'total_usrsctp', 'total_vorbis',\n",
    "    'total_woff2', 'total_wpantund', 'total_yara', 'total_zstd'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n    \"prefix\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 102, 123, 54],\\n    \\n    \"prefix-ids\":[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"TBBox_Rec_\", \"\"],\\n    \\n    \"postfix\": [123, 37, 123, 72, 123, 8, 123, 85, 123, 72, 123, 8, 123, 48, 123, 8, 123, 55, 52, 91, 123, 8, 123, 37, 123, 72, 123, 8, 123, 85, 123, 72, 123, 8, 123, 57, 123, 8, 123, 55, 52, 54, 30, 54, 85, 123, 97, 123, 22, 123, 97, 123, 55, 123, 53, 99, 91, 123, 84, 91, 123, 123, 91, 123],\\n    \\n    \"postfix-ids\": [\"to\", \"\", \"xMax\", \"\", \"bbox\", \"\", \"user\", \"\", \"xMax\", \"\", \"bbox\", \"\", \"user\", \"\", \"x\", \"\", \"to\", \"\", \"\", \"\", \"x\", \"\", \"to\", \"\", \"xMin\", \"\", \"bbox\", \"\", \"user\", \"\", \"xMin\", \"\", \"bbox\", \"\", \"user\", \"\", \"x\", \"\", \"to\", \"\", \"\", \"\", \"\", \"\", \"\", \"user\", \"\", \"TBBox_Rec\", \"\", \"to\", \"\", \"FT_Vector\", \"\", \"BBox_Move_To\", \"\", \"\", \"\", \"TBBox_Rec\", \"\", \"\", \"bbox\", \"FT_BBox\", \"\", \"last\"],\\n    \\n    \"label-type\": [123],\\n    \\n    \"label-prefix\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\\n    \\n    \"label-postfix\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\\n    \\n    \"case\": 2\\n}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "{\n",
    "    \"prefix\":[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 110, 102, 123, 54],\n",
    "    \n",
    "    \"prefix-ids\":[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"TBBox_Rec_\", \"\"],\n",
    "    \n",
    "    \"postfix\": [123, 37, 123, 72, 123, 8, 123, 85, 123, 72, 123, 8, 123, 48, 123, 8, 123, 55, 52, 91, 123, 8, 123, 37, 123, 72, 123, 8, 123, 85, 123, 72, 123, 8, 123, 57, 123, 8, 123, 55, 52, 54, 30, 54, 85, 123, 97, 123, 22, 123, 97, 123, 55, 123, 53, 99, 91, 123, 84, 91, 123, 123, 91, 123],\n",
    "    \n",
    "    \"postfix-ids\": [\"to\", \"\", \"xMax\", \"\", \"bbox\", \"\", \"user\", \"\", \"xMax\", \"\", \"bbox\", \"\", \"user\", \"\", \"x\", \"\", \"to\", \"\", \"\", \"\", \"x\", \"\", \"to\", \"\", \"xMin\", \"\", \"bbox\", \"\", \"user\", \"\", \"xMin\", \"\", \"bbox\", \"\", \"user\", \"\", \"x\", \"\", \"to\", \"\", \"\", \"\", \"\", \"\", \"\", \"user\", \"\", \"TBBox_Rec\", \"\", \"to\", \"\", \"FT_Vector\", \"\", \"BBox_Move_To\", \"\", \"\", \"\", \"TBBox_Rec\", \"\", \"\", \"bbox\", \"FT_BBox\", \"\", \"last\"],\n",
    "    \n",
    "    \"label-type\": [123],\n",
    "    \n",
    "    \"label-prefix\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    \"label-postfix\": [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "    \n",
    "    \"case\": 2\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"total_aspell\" from \"total_aspell\"\n",
      "Getting data for \"total_aspell\" from \"total_boringssl\"\n",
      "Getting data for \"total_aspell\" from \"total_c-ares\"\n",
      "Getting data for \"total_aspell\" from \"total_exiv2\"\n",
      "Getting data for \"total_aspell\" from \"total_freetype2\"\n",
      "Getting data for \"total_aspell\" from \"total_grok\"\n",
      "Getting data for \"total_aspell\" from \"total_guetzli\"\n",
      "Getting data for \"total_aspell\" from \"total_harfbuzz\"\n",
      "Getting data for \"total_aspell\" from \"total_lcms\"\n",
      "Getting data for \"total_aspell\" from \"total_libarchive\"\n",
      "Getting data for \"total_aspell\" from \"total_libexif\"\n",
      "Getting data for \"total_aspell\" from \"total_libhtp\"\n",
      "Getting data for \"total_aspell\" from \"total_libpng\"\n",
      "Getting data for \"total_aspell\" from \"total_libsndfile\"\n",
      "Getting data for \"total_aspell\" from \"total_libssh\"\n",
      "Getting data for \"total_aspell\" from \"total_libxml2\"\n",
      "Getting data for \"total_aspell\" from \"total_ndpi\"\n",
      "Getting data for \"total_aspell\" from \"total_openthread\"\n",
      "Getting data for \"total_aspell\" from \"total_pcre2\"\n",
      "Getting data for \"total_aspell\" from \"total_proj4\"\n",
      "Getting data for \"total_aspell\" from \"total_re2\"\n",
      "Getting data for \"total_aspell\" from \"total_sqlite3\"\n",
      "Getting data for \"total_aspell\" from \"total_usrsctp\"\n",
      "Getting data for \"total_aspell\" from \"total_vorbis\"\n",
      "Getting data for \"total_aspell\" from \"total_woff2\"\n",
      "Getting data for \"total_aspell\" from \"total_wpantund\"\n",
      "Getting data for \"total_aspell\" from \"total_yara\"\n",
      "Getting data for \"total_aspell\" from \"total_zstd\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, prefix_ids_np,\\\n",
    "postfix_np, postfix_ids_np,\\\n",
    "label_np,\\\n",
    "label_prefix_np, label_postfix_np,\\\n",
    "case_np = data.getTrainData(proj_list, proj_list[target_project], version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_prefix, test_postfix,test_label, test_label_prefix,test_label_postfix, test_case = data.getTestData(proj_list[target_project])\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get target project data\n",
    "'''\n",
    "test_prefix, test_postfix,\\\n",
    "test_label, test_label_prefix,\\\n",
    "test_label_postfix, test_case = data.getTestData(proj_list[target_project])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_np, unuse_prefix,\\\n",
    "prefix_ids_np, unuse_prefix_ids,\\\n",
    "postfix_np, unuse_postfix,\\\n",
    "postfix_ids_np, unuse_postfix_ids,\\\n",
    "label_np, unuse_label,\\\n",
    "label_prefix_np, unuse_label_prefix,\\\n",
    "label_postfix_np, unuse_label_postfix,\\\n",
    "case_np, unuse_case = train_test_split(\n",
    "    prefix_np,\n",
    "    prefix_ids_np,\n",
    "    postfix_np,\n",
    "    postfix_ids_np,\n",
    "    label_np,\n",
    "    label_prefix_np,\n",
    "    label_postfix_np,\n",
    "    case_np,\n",
    "    test_size = 0.5, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, test_prefix,\\\n",
    "train_prefix_ids, test_prefix_ids,\\\n",
    "train_postfix, test_postfix,\\\n",
    "train_postfix_ids, test_postfix_ids,\\\n",
    "train_label, test_label,\\\n",
    "train_label_prefix, test_label_prefix,\\\n",
    "train_label_postfix, test_label_postfix,\\\n",
    "train_case, test_case = train_test_split(\n",
    "    prefix_np,\n",
    "    prefix_ids_np,\n",
    "    postfix_np,\n",
    "    postfix_ids_np,\n",
    "    label_np,\n",
    "    label_prefix_np,\n",
    "    label_postfix_np,\n",
    "    case_np,\n",
    "    test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix,\\\n",
    "train_prefix_ids, val_prefix_ids,\\\n",
    "train_postfix, val_postfix,\\\n",
    "train_postfix_ids, val_postfix_ids,\\\n",
    "train_label, val_label,\\\n",
    "train_label_prefix, val_label_prefix,\\\n",
    "train_label_postfix, val_label_postfix,\\\n",
    "train_case, val_case = train_test_split(\n",
    "    train_prefix,\n",
    "    train_prefix_ids,\n",
    "    train_postfix,\n",
    "    train_postfix_ids,\n",
    "    train_label,\n",
    "    train_label_prefix,\n",
    "    train_label_postfix,\n",
    "    train_case,\n",
    "    test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  339916\n",
      "validation:  84980\n",
      "test:  106224\n"
     ]
    }
   ],
   "source": [
    "print('train: ', len(train_label))\n",
    "print('validation: ', len(val_label))\n",
    "print('test: ', len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, val_prefix, test_prefix,\n",
    "        train_prefix_ids, val_prefix_ids, test_prefix_ids,\n",
    "\n",
    "        train_postfix, val_postfix, test_postfix,\n",
    "        train_postfix_ids, val_postfix_ids, test_postfix_ids,\n",
    "\n",
    "        train_label, val_label, test_label,\n",
    "\n",
    "        train_label_prefix, val_label_prefix, test_label_prefix,\n",
    "        train_label_postfix, val_label_postfix, test_label_postfix,\n",
    "\n",
    "        train_case, val_case, test_case,\n",
    "\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "overall_title = 'version3_'\n",
    "title = overall_title + '01'\n",
    "epochs = 20 \n",
    "\n",
    "# max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "embed_dim = 100 # 100\n",
    "hidden_size = 200 # 200\n",
    "n_layers = 1\n",
    "output_size = 1 # max(token_choices) + 1\n",
    "dropout = 0.0\n",
    "max_length = 64 # max_len\n",
    "input_size = 154 # max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"BCE\"\n",
    "\n",
    "teacher_forcing_ratio = 0.75\n",
    "threshold = torch.tensor([0.5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (pointer): PointerNetwork(\n",
      "    (fc1): Linear(in_features=808, out_features=400, bias=True)\n",
      "    (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "    (dp1): Dropout(p=0.0, inplace=False)\n",
      "    (dp2): Dropout(p=0.0, inplace=False)\n",
      "    (dp3): Dropout(p=0.0, inplace=False)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, loss_fn, optimizer = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device,\n",
    "    loss_fn_name=loss_fn_name\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Train Loss  | Train Acc  | Val Loss | Val Acc | Elapsed\n",
      "--------------------------------------------------------------------------------\n",
      "   1    |   0.162741   | 94.619564  | 0.142565 | 93.87  | 577.04\n",
      "   2    |   0.139419   | 95.035617  | 0.135370 | 93.41  | 530.47\n",
      "   3    |   0.132131   | 95.218646  | 0.129238 | 92.89  | 528.82\n",
      "   4    |   0.126915   | 95.361272  | 0.125266 | 92.82  | 528.22\n",
      "   5    |   0.124669   | 95.403586  | 0.123949 | 93.37  | 528.52\n",
      "   6    |   0.123150   | 95.469211  | 0.121460 | 92.97  | 528.15\n",
      "   7    |   0.121071   | 95.539878  | 0.120643 | 91.06  | 526.54\n",
      "   8    |   0.118852   | 95.595405  | 0.118157 | 92.57  | 527.32\n",
      "   9    |   0.117620   | 95.623355  | 0.117091 | 92.65  | 531.36\n",
      "  10    |   0.115873   | 95.681875  | 0.115895 | 92.03  | 528.36\n",
      "  11    |   0.114498   | 95.720478  | 0.114907 | 92.51  | 528.49\n",
      "  12    |   0.113445   | 95.736442  | 0.114484 | 92.14  | 529.03\n",
      "  13    |   0.112211   | 95.766637  | 0.113821 | 90.82  | 528.90\n",
      "  14    |   0.110903   | 95.796999  | 0.111905 | 92.12  | 539.21\n",
      "  15    |   0.109635   | 95.824698  | 0.110774 | 92.48  | 527.97\n",
      "  16    |   0.108538   | 95.844262  | 0.110318 | 92.28  | 530.93\n",
      "  17    |   0.107851   | 95.869310  | 0.109830 | 91.96  | 529.35\n",
      "  18    |   0.106642   | 95.883398  | 0.108952 | 92.44  | 527.31\n",
      "  19    |   0.105868   | 95.899445  | 0.108783 | 92.11  | 529.65\n",
      "  20    |   0.104786   | 95.917810  | 0.107662 | 92.00  | 529.82\n",
      "\n",
      "\n",
      "Training complete! Best accuracy: 93.87%.\n"
     ]
    }
   ],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.saveModel(overall_title, title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(154, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (pointer): PointerNetwork(\n",
      "    (fc1): Linear(in_features=808, out_features=400, bias=True)\n",
      "    (fc2): Linear(in_features=400, out_features=200, bias=True)\n",
      "    (fc3): Linear(in_features=200, out_features=1, bias=True)\n",
      "    (dp1): Dropout(p=0.0, inplace=False)\n",
      "    (dp2): Dropout(p=0.0, inplace=False)\n",
      "    (dp3): Dropout(p=0.0, inplace=False)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mu.getModel(overall_title, title)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.10804180332892652\n",
      "test acc:  95.86014887971699\n",
      "TT acc:  49.93396226415094\n",
      "saved precision and recall results to file!\n"
     ]
    }
   ],
   "source": [
    "loss, acc, TT_acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    fn=overall_title,\n",
    "    proj_nm=title,\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\t |\\t TT acc: ' + str(TT_acc)\n",
    "        # text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(0.0, 3)) + ' min\\t |\\t TT acc: ' + str(TT_acc)\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded model graph to tensorboard!\n"
     ]
    }
   ],
   "source": [
    "mu.graphModel(train_dataloader, model, writer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
