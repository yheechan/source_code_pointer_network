{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list =[\n",
    "    'boringssl', 'c-ares',\n",
    "    'freetype2', 'guetzli',\n",
    "    'harfbuzz', 'libpng',\n",
    "    'libssh', 'libxml2',\n",
    "    'pcre', 'proj4',\n",
    "    'r32', 'sqlite3',\n",
    "    'vorbis', 'woff2',\n",
    "    'wpantund'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_project = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch, gc\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "import timeit\n",
    "\n",
    "import data\n",
    "import data_loader as dl\n",
    "import initializer as init\n",
    "import trainer\n",
    "import tester\n",
    "# import predictor\n",
    "import model_util as mu\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# print(torch.cuda.memory_summary(device=None, abbreviated=False))\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprefix = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 134, 56, 2, 47]\\npostfix = [2, 124, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 49, 48, 2, 56, 134, 91, 2, 121, 91, 2, 121, 91, 2, 2, 47, 2, 56, 134, 128, 50, 88, 48, 2, 47, 2, 124, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 49, 48, 2, 121, 91, 2]\\nlabel-type = [2]\\nlabel-prefix = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\\nlabel-postfix = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\\ncase = 2\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "prefix = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 128, 134, 56, 2, 47]\n",
    "postfix = [2, 124, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 49, 48, 2, 56, 134, 91, 2, 121, 91, 2, 121, 91, 2, 2, 47, 2, 56, 134, 128, 50, 88, 48, 2, 47, 2, 124, 88, 48, 48, 2, 47, 89, 48, 2, 47, 47, 49, 48, 2, 121, 91, 2]\n",
    "label-type = [2]\n",
    "label-prefix = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "label-postfix = [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
    "case = 2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for \"freetype2\" from \"boringssl\"\n"
     ]
    }
   ],
   "source": [
    "# get all data exept target project\n",
    "prefix_np, postfix_np,\\\n",
    "label_np, label_prefix_np,\\\n",
    "label_postfix_np, case_np = data.getTrainData(proj_list, proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get target project data\n",
    "test_prefix, test_postfix,\\\n",
    "test_label, test_label_prefix,\\\n",
    "test_label_postfix, test_case = data.getTestData(proj_list[target_project])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix, val_prefix,\\\n",
    "train_postfix, val_postfix,\\\n",
    "train_label, val_label,\\\n",
    "train_label_prefix, val_label_prefix,\\\n",
    "train_label_postfix, val_label_postfix,\\\n",
    "train_case, val_case = train_test_split(\n",
    "    prefix_np, postfix_np,\\\n",
    "    label_np, label_prefix_np,\\\n",
    "    label_postfix_np, case_np,\\\n",
    "    test_size = 0.2, random_state = 43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, val_dataloader, test_dataloader =\\\n",
    "    dl.data_loader(\n",
    "        train_prefix, val_prefix,\n",
    "        train_postfix, val_postfix,\n",
    "        train_label, val_label,\n",
    "        train_label_prefix, val_label_prefix,\n",
    "        train_label_postfix, val_label_postfix,\n",
    "        train_case, val_case,\n",
    "\n",
    "\n",
    "        test_prefix, test_postfix,\n",
    "        test_label, test_label_prefix,\n",
    "        test_label_postfix, test_case,\n",
    "\n",
    "        batch_size=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_title = 'look2prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('../tensorboard/'+overall_title+'/tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# set parameters here\n",
    "# ====================\n",
    "\n",
    "title = overall_title + '_' + proj_list[target_project] + '_tryBCE'\n",
    "epochs = 20 \n",
    "\n",
    "# max_len, source_code_tokens, token_choices = data.getInfo()\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0\n",
    "\n",
    "embed_dim = 100 # 100\n",
    "hidden_size = 200 # 200\n",
    "n_layers = 1\n",
    "output_size = 1 # max(token_choices) + 1\n",
    "dropout = 0.0\n",
    "max_length = 64 # max_len\n",
    "input_size = 214 # max(token_choices) + 1\n",
    "device = device\n",
    "\n",
    "model_name = \"seq2seq\"\n",
    "optim_name = \"Adam\"\n",
    "loss_fn_name = \"BCE\"\n",
    "\n",
    "teacher_forcing_ratio = 0.75\n",
    "threshold = torch.tensor([0.5]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (pointer): PointerNetwork(\n",
      "    (fc): Linear(in_features=800, out_features=1, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "trainer.set_seed(42)\n",
    "\n",
    "model, loss_fn, optimizer = init.initialize_model(\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    embed_dim=embed_dim,\n",
    "    hidden_size=hidden_size,\n",
    "    n_layers=n_layers,\n",
    "    output_size=output_size,\n",
    "    dropout=dropout,\n",
    "    max_length=max_length,\n",
    "    input_size=input_size,\n",
    "    device=device,\n",
    "    loss_fn_name=loss_fn_name\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "trainer.train(\n",
    "    epochs=epochs,\n",
    "    title=title,\n",
    "    writer=writer,\n",
    "    teacher_forcing_ratio=teacher_forcing_ratio,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    device=device,\n",
    "    threshold=threshold\n",
    ")\n",
    "\n",
    "end_time = (timeit.default_timer() - start_time) / 60.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu.saveModel(overall_title, title, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySeq2Seq(\n",
      "  (prefixEncoder): Encoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (postfixEncoder): Encoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "    (hidden_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (cell_fc): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(214, 100)\n",
      "    (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
      "  )\n",
      "  (pointer): PointerNetwork(\n",
      "    (fc): Linear(in_features=800, out_features=1, bias=True)\n",
      "    (dp): Dropout(p=0.0, inplace=False)\n",
      "    (sigmoid): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = mu.getModel(overall_title, title)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss:  0.162094375322239\n",
      "test acc:  95.53194444444443\n",
      "TT acc:  40.46666666666667\n"
     ]
    }
   ],
   "source": [
    "loss, acc = tester.test(\n",
    "    test_dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    loss_fn=loss_fn,\n",
    "    device=device,\n",
    "    fn=overall_title,\n",
    "    proj_nm=title,\n",
    "    threshold=threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../stat/'+overall_title, 'a') as f:\n",
    "        text = title + '\\t |\\tloss: ' + str(loss) + '\\t |\\tacc: ' + str(acc) + '\\t |\\t time: ' + str(round(end_time, 3)) + ' min\\n'\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.graphModel(train_dataloader, model, writer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "348b9cd948ce87438be2e622031b2ecfa29bc2d3ecc0fd03127b9a24b30227df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
